{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 - The cross entropy loss VS. The hinge loss\n",
    "\n",
    "Cross-entropy loss is defined as </p> \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_{CE} = - \\sum_{i=1}^{n} t_{i}log(p_i)\n",
    "\\end{aligned}\n",
    "$$\n",
    "for n classes. Where $ t_i $ is the true label and $p_i$ is the softmax probability for the $i^{th}$ class. </p>\n",
    "\n",
    "Hinge loss is defined as </p>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_{hinge(binary)(\\tilde{y}, y)} = max(0, 1-y \\cdot \\tilde{y})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and </p> \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_{hinge(multi-class)(\\hat{y}, y)} = max(0, 1-\\hat{y}_{[t]} \\cdot \\hat{y}_{[t]})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As we can see from these functions, hinge loss does not consider class probability and only focuses on relevant examples. So, hinge loss would be more ideal when we either need a hard decision role or we don't want our classification model influenced by too much information. </p>\n",
    "\n",
    "For example, in a binary classification problem with very sparse data, hinge loss will be more effective than cross-entropy loss. When there are many outliers in our data, hinge loss can avoid punishing our model due to the outliers. It is also faster since we don't need to consider probabilities.  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 - Gradient Descent\n",
    "\n",
    "##### (a) Briefly describe how you would determine the correct learning rate to use in gradient descent.\n",
    "\n",
    "An optimal learning rate for gradient descent should reduce the loss steadily until it reache a stable level. We could determine this by observing the reduction of $L(\\theta)$. If $L(\\theta)$ does not change during gradient descent and remains high, that means the current learning rate $\\eta$ is too small. If $L(\\theta)$ fluctuates drastically or drops very low immediately, it means the current learning rate $\\eta$ is too big.\n",
    "\n",
    "##### (b) What is the advantage of minibatch stochastic gradient descent over regular stochastic gradient descent.\n",
    "\n",
    "In comparison with regular stochastic gradient descent, minibatch stochastic gradient descent considers a small set of examples at each time. This makes it better at avoiding being influenced by big outliers and finding the minima point. It will also improve the speed of convergence because regular SGD will dance around the minima at a certain point.\n",
    "\n",
    "Minibatch stochastic gradient descent is especially good at handling saddle points. Because it considers multiple examples, it avoids being stuck in a saddle point like regular stochastic gradient descent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 - Validation curves\n",
    "\n",
    "##### (a)\n",
    "\n",
    "As regularization parameter $\\lambda$ increases, the model punishes heavier on overfitting. So the training error should increase and the validation error should decrease.\n",
    "\n",
    "![alt text](3-a.png)\n",
    "\n",
    "##### (b)\n",
    "\n",
    "As $k$ increases, the model becomes more and more complicated. So it fits better with training data and eventually becomes overfit. So the training error should decrease and the validation error increases.\n",
    "\n",
    "![alt text](3-b.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 - Regularization\n",
    "\n",
    "L1 regularization (Lasso regularization) has penalty term: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\lambda \\sum_{j=1}^{p} |\\beta_{j}|,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "whereas L2 regularization (Ridge regularization) has penalty term:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\lambda \\sum_{j=1}^{p} \\beta_{j}^{2}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Because the square, $l2$ regularization penalizes large features more than small features, whereas $l1$ regularization penalizes features evenly regardless how big they are. For $l1$ regularization, adding smaller weights may not be helpful to reduce loss since the equal punishment would cancel out the improvement. </p> \n",
    "\n",
    "For example, suppose $w_1 = 10, w_2 = 2$. $l1$ regularization would be indifferent towards reducing these 2 weights by 1 because the penalty is 1 for both weights. But $l2$ regularization would prefer reducing $w_1$ by 1 instead of $w_2$. Because the penalty reduction from $w_1$ is $ 10^2 - 9^2 = 9$ and the penalty reduction from $w_2$ is $ 2^2 - 1^2 = 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
